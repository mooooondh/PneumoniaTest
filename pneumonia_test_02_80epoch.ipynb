{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.load(\"./array/X_train.npy\")\n",
    "y_train= np.load(\"./array/y_train.npy\")\n",
    "X_test= np.load(\"./array/X_test.npy\")\n",
    "y_test= np.load(\"./array/y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5214, 224, 224, 1)\n",
      "(5214,)\n",
      "(624, 224, 224, 1)\n",
      "(624,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model= keras.applications.resnet50.ResNet50(weights= None, classes= 2, input_shape= (224, 224, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss= \"sparse_categorical_crossentropy\", optimizer= \"sgd\", metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,585,538\n",
      "Trainable params: 23,532,418\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  2/326 [..............................] - ETA: 33s - loss: 1.4643 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0808s vs `on_train_batch_end` time: 0.1260s). Check your callbacks.\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.6674 - accuracy: 0.8312\n",
      "Epoch 2/80\n",
      "326/326 [==============================] - 66s 204ms/step - loss: 0.2676 - accuracy: 0.9148\n",
      "Epoch 3/80\n",
      "326/326 [==============================] - 67s 205ms/step - loss: 0.1792 - accuracy: 0.9411\n",
      "Epoch 4/80\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.1755 - accuracy: 0.9448\n",
      "Epoch 5/80\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.1354 - accuracy: 0.9498\n",
      "Epoch 6/80\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.1235 - accuracy: 0.9584\n",
      "Epoch 7/80\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.1091 - accuracy: 0.9618\n",
      "Epoch 8/80\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 0.0931 - accuracy: 0.9684\n",
      "Epoch 9/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0969 - accuracy: 0.9668\n",
      "Epoch 10/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0761 - accuracy: 0.9766\n",
      "Epoch 11/80\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.0823 - accuracy: 0.9708\n",
      "Epoch 12/80\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.0752 - accuracy: 0.9743\n",
      "Epoch 13/80\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.0727 - accuracy: 0.9758\n",
      "Epoch 14/80\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.0534 - accuracy: 0.9787\n",
      "Epoch 15/80\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.0433 - accuracy: 0.9845\n",
      "Epoch 16/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0489 - accuracy: 0.9829\n",
      "Epoch 17/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0449 - accuracy: 0.9848\n",
      "Epoch 18/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 19/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0332 - accuracy: 0.9877\n",
      "Epoch 20/80\n",
      "326/326 [==============================] - 69s 210ms/step - loss: 0.0350 - accuracy: 0.9871\n",
      "Epoch 21/80\n",
      "326/326 [==============================] - 68s 209ms/step - loss: 0.0283 - accuracy: 0.9918\n",
      "Epoch 22/80\n",
      "326/326 [==============================] - 68s 209ms/step - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 23/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0232 - accuracy: 0.9918s - loss:\n",
      "Epoch 24/80\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 25/80\n",
      "326/326 [==============================] - 70s 214ms/step - loss: 0.0342 - accuracy: 0.9885\n",
      "Epoch 26/80\n",
      "326/326 [==============================] - 68s 210ms/step - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 27/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 28/80\n",
      "326/326 [==============================] - 67s 207ms/step - loss: 0.0086 - accuracy: 0.9967\n",
      "Epoch 29/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0179 - accuracy: 0.9952\n",
      "Epoch 30/80\n",
      "326/326 [==============================] - 67s 205ms/step - loss: 0.0116 - accuracy: 0.9967\n",
      "Epoch 31/80\n",
      "326/326 [==============================] - 67s 205ms/step - loss: 0.0149 - accuracy: 0.9941\n",
      "Epoch 32/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0165 - accuracy: 0.9941\n",
      "Epoch 33/80\n",
      "326/326 [==============================] - 73s 224ms/step - loss: 0.0270 - accuracy: 0.9921\n",
      "Epoch 34/80\n",
      "326/326 [==============================] - 72s 221ms/step - loss: 0.0285 - accuracy: 0.9908\n",
      "Epoch 35/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 36/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 37/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 38/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 39/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 40/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 41/80\n",
      "326/326 [==============================] - 70s 215ms/step - loss: 0.0112 - accuracy: 0.9960\n",
      "Epoch 42/80\n",
      "326/326 [==============================] - 72s 222ms/step - loss: 0.0178 - accuracy: 0.9942\n",
      "Epoch 43/80\n",
      "326/326 [==============================] - 71s 219ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 44/80\n",
      "326/326 [==============================] - 71s 217ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 45/80\n",
      "326/326 [==============================] - 69s 212ms/step - loss: 0.0029 - accuracy: 0.9992s - loss: 0.0029 - accuracy: 0.\n",
      "Epoch 46/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 47/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 48/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 49/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 50/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 0.0052 - accuracy: 0.9975\n",
      "Epoch 51/80\n",
      "326/326 [==============================] - 68s 209ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 52/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 53/80\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 54/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0039 - accuracy: 0.9983\n",
      "Epoch 55/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 56/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0062 - accuracy: 0.9975\n",
      "Epoch 57/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 58/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 59/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 60/80\n",
      "326/326 [==============================] - 68s 208ms/step - loss: 6.9954e-04 - accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "326/326 [==============================] - 70s 213ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 62/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 8.8202e-04 - accuracy: 0.9996\n",
      "Epoch 63/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 5.2628e-04 - accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 2.1754e-04 - accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 9.8633e-04 - accuracy: 0.9996\n",
      "Epoch 66/80\n",
      "326/326 [==============================] - 70s 216ms/step - loss: 4.0636e-04 - accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 0.0026 - accuracy: 0.9988\n",
      "Epoch 68/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 69/80\n",
      "326/326 [==============================] - 68s 207ms/step - loss: 4.6897e-04 - accuracy: 0.9998\n",
      "Epoch 70/80\n",
      "326/326 [==============================] - 68s 210ms/step - loss: 7.4027e-04 - accuracy: 0.9996\n",
      "Epoch 71/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 5.5375e-04 - accuracy: 0.9996\n",
      "Epoch 72/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 1.9625e-04 - accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "326/326 [==============================] - 69s 211ms/step - loss: 1.9226e-04 - accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "326/326 [==============================] - 69s 213ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 75/80\n",
      "326/326 [==============================] - 67s 206ms/step - loss: 6.7893e-04 - accuracy: 0.9996\n",
      "Epoch 76/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 6.1217e-04 - accuracy: 0.9998\n",
      "Epoch 77/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 8.1893e-04 - accuracy: 0.9996\n",
      "Epoch 78/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 6.2383e-04 - accuracy: 0.9998\n",
      "Epoch 79/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 5.2155e-04 - accuracy: 0.9998\n",
      "Epoch 80/80\n",
      "326/326 [==============================] - 67s 204ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "time:  5508.5785982608795\n"
     ]
    }
   ],
   "source": [
    "    start_time= time.time()\n",
    "    history= model.fit(X_train, y_train, epochs= 80, batch_size= 16)#, validation_data= (X_val, y_val))\n",
    "    end_time= time.time()\n",
    "print(\"time: \", end_time- start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\app\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\app\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model/PneumoniaTest_ResNet50_80epoch\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./model/PneumoniaTest_ResNet50_80epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= load_model(\"./model/PneumoniaTest_ResNet50_80epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize= (8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)\n",
    "\n",
    "y_hat=[]\n",
    "\n",
    "for i in y_pred:\n",
    "    if (i[0]> i[1]):\n",
    "        y_hat.append(0)\n",
    "    else:\n",
    "        y_hat.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.842948717948718\n"
     ]
    }
   ],
   "source": [
    "accuracy= 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i]== y_hat[i]):\n",
    "        accuracy+= 1\n",
    "        \n",
    "print(\"accuracy: \", accuracy/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val= np.load(\"./array/X_val.npy\")\n",
    "y_val= np.load(\"./array/y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred= model.predict(X_val)\n",
    "\n",
    "y_val_hat= []\n",
    "\n",
    "for i in y_val_pred:\n",
    "    if (i[0]> i[1]):\n",
    "        y_val_hat.append(0)\n",
    "    else:\n",
    "        y_val_hat.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.875\n"
     ]
    }
   ],
   "source": [
    "accuracy= 0\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    if(y_val[i]== y_val_hat[i]):\n",
    "        accuracy+= 1\n",
    "        \n",
    "print(\"accuracy: \", accuracy/len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
